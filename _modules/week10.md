---
title: Week 10, Apr. 2/3
---

### Reasoning, Knowledge States, and Compositionality

Can language models engage in complex, multi-step logical reasoning? We survey various Turing tests for reasoning skills, as well as ways to help language models reason better. Guest lecturer Will Merrill, an NYU PhD student in Data Science, will tell us about theoretical limitations imposed by the Transformer architecture on language model reasoning abilities.

Lecture
: Interpretability and model analysis, targeted challenge benchmarks, attention visualization, probing

Lab
: TBD

Reading
: [Kojima et al. (2022)](https://arxiv.org/abs/2205.11916), [Saparov and He (2023)](https://arxiv.org/abs/2210.01240), and [Saparov et al. (2023)](https://arxiv.org/abs/2305.15269), on multi-hop reasoning via chain-of-thought prompting
: [Li et al. (2018)](https://arxiv.org/abs/2106.00737) and [Kim and Schuster (2023)](https://arxiv.org/abs/2305.02363), on world models and entity state tracking
: [Lake and Baroni (2018)](https://arxiv.org/abs/1711.00350), [Hupkes et al. (2020)](https://arxiv.org/abs/1908.08351), and [Kim and Linzen (2020)](https://arxiv.org/abs/2010.05465), on compositionality
: [Weiss et al. (2021)](https://arxiv.org/abs/2106.06981), [Merrill et al. (2022)](https://arxiv.org/abs/2106.16213), and [Merrill and Sabharwal (2023)](https://arxiv.org/abs/2310.07923), on the computational expressive power of Transformers