---
title: Week 6, Feb. 27/28
---

### Language Modeling and General Intelligence

Language modeling—the task of predicting what word comes after a string of text from a document—is one of the most fundamental techniques in NLP. Recent advances have shown that highly competent language models exhibit a number of general AI abilities, even if they are not trained on any objective other than word prediction. We explore the technique of prompting, which attempts to solve NLP tasks using the emergent abilities of large language models.

Lecture
: Large language models, prompting and few-shot learning, scaling and inverse scaling

Lab
: TBD

Reading
: **Tutorial**{: .label .label-yellow } Alammar's (2019) tutorials on [GPT-2](https://jalammar.github.io/illustrated-gpt2/) and [GPT-3](https://jalammar.github.io/how-gpt3-works-visualizations-animations/)
: [The GPT-2 paper (Radford et al., 2019)](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf), on language modeling as a general intelligence problem
: [The GPT-3 paper (Brown et al., 2020)](https://arxiv.org/abs/2005.14165) and [Wei et al. (2022a)](https://arxiv.org/abs/2201.11903), on prompting
: [Srivastava et al. (2022)](https://arxiv.org/abs/2206.04615) and [Wei et al. (2022b)](https://arxiv.org/abs/2206.07682), on scale and emergent abilities
: [Lin et al. (2022)](https://arxiv.org/abs/2109.07958), [McKenzie et al. (2023)](https://arxiv.org/abs/2306.09479), and [Wei et al. (2023)](https://arxiv.org/abs/2211.02011), on inverse scaling