---
title: Week 11, Apr. 9/10
---

### Logic and Reasoning

Can language models engage in complex, multi-step logical reasoning? We survey various Turing tests for reasoning skills, as well as ways to help language models reason better. Guest lecturer Will Merrill, an NYU PhD student in Data Science, will tell us about theoretical limitations imposed by the Transformer architecture on language model reasoning abilities.


Lecture
: Circuit complexity, AC<sup>0</sup> and TC<sup>0</sup>, expressive power of the Transformer
: [Slides](https://docs.google.com/presentation/d/11LNO0YM4GcfgrI2Xc6Lgcxz93qs-MbMJNiZDtFYdk1o/edit?usp=sharing), [Zoom Recording](https://nyu.zoom.us/rec/share/-_CR4LWuznfplG5ayj-1fLgBKpNgc7lo4Y55Rq_vGeDIS743E-J9ya8N_0mTkxBi.HvAN9oBp3QZM_k64)

Lab
: Linguistic evaluation of language models
: [Colab Notebook](https://colab.research.google.com/drive/12VNVFvZtDjPwqDdsksVnImY3vFxvrEqs?usp=sharing)

Reading
: [Kojima et al. (2022)](https://arxiv.org/abs/2205.11916), [Saparov and He (2023)](https://arxiv.org/abs/2210.01240), [Saparov et al. (2023)](https://arxiv.org/abs/2305.15269), and [Press et al. (2023)](https://arxiv.org/abs/2210.03350), on multi-hop reasoning
: [Li et al. (2018)](https://arxiv.org/abs/2106.00737) and [Kim and Schuster (2023)](https://arxiv.org/abs/2305.02363), on world models and entity state tracking
: [Weiss et al. (2021)](https://arxiv.org/abs/2106.06981), [Merrill et al. (2022)](https://arxiv.org/abs/2106.16213), and [Merrill and Sabharwal (2023)](https://arxiv.org/abs/2310.07923), on the computational expressive power of Transformers
: [Yang et al. (2023)](https://arxiv.org/abs/2306.15626) and [Trinh et al. (2024)](https://www.nature.com/articles/s41586-023-06747-5): enhancing the reasoning capabilities of language models



Dates
: <span>RQ 5 Released Fri 4/12</span>{:.label.label-green} 