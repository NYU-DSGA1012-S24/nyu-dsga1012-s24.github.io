---
title: Week 1, Jan. 23/24
---

### What Is Meaning?

We introduce the concept of meaning in natural language, taking inspiration from linguists, philosophers, and data scientists. We learn about the word2vec model of semantics and examine in what sense and to what extent it models the "meaning" of individual words.

Topics
: Lexical semantics, word embeddings, the distributional hypothesis

<!--
Lecture
: [Slides](https://drive.google.com/file/d/1w6hHItHkn3R7QI1AiN9500J5cSRdOCTT/view?usp=share_link), 
[Zoom Recording](https://nyu.zoom.us/rec/share/6CGMe6KzGdXMsh2vN0_0o8pAi3inExMjoA38xgWQEI8RYR1BdEKzGrnu9hnxFk8S.HQiIXcuZe6JCU0th?startTime=1674572102000)

Lab
: [Colab Notebook](https://colab.research.google.com/drive/1ehOgBO1iqIITO5T1w5SN5ExhPPs-nSrR?usp=sharing),
[Zoom Recording](https://nyu.zoom.us/rec/share/uoPqYrtBEgIO8ihJqpaat0xKCCGJ2yHYqVJw5ayYDsZFxdthEpfWzog2_Gxbcur-.77NL8dp_0H7QQl-L)

Reading
: **Ling2**{: .label .label-yellow }
[\#18–19, \#21–24](https://www.morganclaypool.com/doi/abs/10.2200/S00935ED1V02Y201907HLT043), on lexical semantics
: **Notes**{: .label .label-yellow }
[on vector semantics](https://drive.google.com/file/d/16vWNLaCFEmnW2kxhsCGkd5OXPEMgKl7v/view?usp=share_link)
(skip-gram with negative sampling)
: **D2L**{: .label .label-yellow }
[Sections 15.1, 15.5–15.7](https://d2l.ai/chapter_natural-language-processing-pretraining/word2vec.html), on various 
word
embedding models
: [Mikolov et al. (2013)](https://arxiv.org/abs/1301.3781), the original word2vec paper

-->