---
layout: home
title: Basic Information 
nav_order: 1
permalink: /:path/
seo:
  type: Course
  name: Just the Class
---

# Natural Language Understanding and Computational Semantics

**DS-GA 1012/LING-GA 1012, Spring 2024**<br />
**New York University**

Since at least the proposal of the Turing test, building computational systems that can communicate with humans using natural language has been a central goal for Al research. Understanding real, naturally occurring human language is the key to reaching this goal. This course surveys recent successes in language understanding and prepares students to do original research in this area, culminating with a substantial final project. 

## Course Staff

#### Instructor

* Sophie Hao **she/her**{: .label } (NYU email: `sophie.hao`)

#### Section Leaders

* Cara Leong **she/her**{: .label } (NYU email: `caraleong`)
* Jackson Petty **he/him**{: .label } (NYU email: `jp6664`)

#### Graders

* Anisha Bhatnagar **she/her**{: .label } (NYU email: `ab10945`)
* Manoj Middepogu **he/him**{: .label } (NYU email: `mm12799`) 
* Nori Naka **he/him**{: .label } (NYU email: `nn1331`) 

## Logistics

Class sessions take place in-person and on Zoom. Recordings will be provided. Office hours may be in-person and/or on Zoom, at the discretion of the person holding the office hours.

#### Lectures

Tuesdays, 6:45 PM–8:25 PM, with Sophie<br />
Room G08, [12 Waverly Place](https://goo.gl/maps/3qye7472KPRqERbi8) and on [Zoom](https://nyu.zoom.us/j/92219995802?pwd=Tm9jNVdtWkVwazd6cUxEU0h0K2ZZZz09)

#### Lab

Wednesdays, 7:10 PM–8:00 PM, with Cara or Jackson<br />
Room 102, [19 University Place](https://maps.app.goo.gl/gZFoDtF17dD4VAH97) and on [Zoom](https://nyu.zoom.us/j/92219995802?pwd=Tm9jNVdtWkVwazd6cUxEU0h0K2ZZZz09)

#### Office Hours

Wednesdays, 5:00 PM–6:00 PM, with Cara<br />
Room 307, [Arthur L. Carter Hall (10 Washington Place)](https://maps.app.goo.gl/AUKATEnYwBccmE4v8)

Fridays, 11:00 AM–12:00 PM, with Sophie<br />
Room 700, [60 5th Avenue](https://maps.app.goo.gl/vmJ9bgaZyJDrRj5c6) and on [Zoom](https://nyu.zoom.us/j/92219995802?pwd=Tm9jNVdtWkVwazd6cUxEU0h0K2ZZZz09)

## Prerequisites

Students are expected to have had some experience with most of the following concepts.

{: .note }
> #### Calculus and Linear Algebra
> Partial derivatives, gradients, vectors, matrices, matrix multiplication, vector spaces
>
> #### Probability and Statistics
> Probability distributions, conditional probabilities, Bayes's theorem, linear regression
>
> #### Machine Learning and Data Science
> Features (discrete vs. continuous), optimization, train/dev/test, dimensionality reduction (e.g., PCA), deep learning
>
> #### Python Programming
> Basic syntax, iterables/comprehension, Jupyter notebooks, package managers (e.g., `pip`), modules, object-oriented programming, data types
>
> #### Natural Language Processing
> Tokenization, vector semantics, language modeling

Since this is a graduate-level course with students from a diverse array of backgrounds (data science, computer science, linguistics, and undergrads), many students will be unfamiliar with one or more of the above topics. This is okay, as long as you feel comfortable looking up anything that you don't understand or asking for help when necessary. 

## Is This the Right Course for Me?

NYU has three natural language processing (NLP) courses at the graduate level:

* CSCI-GA 2590, Natural Language Processing
* DS-GA 1011, Natural Language Processing with Representation Learning
* DS-GA 1012, Natural Language Understanding and Computational Semantics

DS-GA 1012 (this course) is the only graduate-level NLP course offered this semester. An undergraduate-level NLP course (CSCI-UA 480) is being offered by Adam Meyers, and NLP courses are also being offered at NYU Abu Dhabi (CS-UH 2216) and NYU Shanghai (CSCI-SHU 376).

DS-GA 1012 differs from CSCI-GA 2590 and DS-GA 1011 in its focus on cutting-edge research in the area of language understanding. CSCI-GA 2590 and DS-GA 1011 usually cover similar material, and are dedicated to teaching you the basic techniques of NLP in depth: word embeddings, deep learning, sequence modeling, transfer learning, large language models, and alignment. In DS-GA 1012 we will spend the first half of the semester reviewing these techniques quickly, at a high level. We will skip several topics, such as recurrent architectures, in order to get you caught up to the state of the art as soon as possible. After spring break, we will survey recent NLP research surrounding the question of whether modern language models such as ChatGPT understand the meaning of natural language. Along the way, we will be thinking critically about what "meaning" is, what it means for an AI system to "understand" it, and how to distinguish true intelligence from a complicated bag of tricks.

Many former students of DS-GA 1012 have gone on to take CSCI-GA 2590 or DS-GA 1011, and _vice versa_.
